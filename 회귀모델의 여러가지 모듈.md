회귀모델 
==
여러가지 모듈 
--
### 1. statsmodels의 formula 모듈 (R의 formula 문법과 유사)
* ```ols('y ~ x')``` # 선형 회귀 (최소제곱법; ordinary least squares)
* ```logit('y ~ x')``` # 로지스틱 회귀 (최대우도법으로 추정하여 모델 적합) 
```python
from statsmodels.formula.api import ols  # 문자열
model = ols('y~ x1 + x2', data = ~)
lr = model.fit()  # 학습
lr.summary()
```
### 2. statsmodels의 api 모듈 
* 특징 : 모델에 <mark>절편</mark>이 포함되지 않아 상수항 추가해줘야 함 ★
* ```OLS(y,X)``` # 선형 회귀 
* ```Logit(y,X)``` # 로지스틱 회귀 
```python
import statsmodels.api as sm
...
X = sm.add_constant(X) # 상수항(절편항) 추가
model = sm.OLS(y, X)

lr = model.fit() # 학습
lr.summary()
```
#### statsmodels의 summary()에서 제공하는 파라미터 
```python
print(lr.params) # 회귀 계수
print(lr.rsquared) # 결정 계수
print(lr.rsquared_adj) # 수정된 결정 계수
print(lr.pvalues) # 회귀 계수 검정 p value
print(lr.tvalues) # 회귀 계수 검정 t 통계량
print(lr.conf_int()) # 95% 회귀 계수 추정치 신뢰구간
print(lr.mse_resid) ## MSE
print(lr.fittedvalues) ## 적합값 y_hat in-sample prediction (= results.predict(X))
print(lr.resid) ## 잔차 y-y_hat
```


### 3. sklearn의 linear_model 모듈 (대표적으로 LinearRegression/ LogisticRegression)
* LinearRegression()
* LogisticRegression()
```python
from sklearn.linear_model import LinearRegression 
model = LinearRegression()
lr = model.fit(X_train, y_train) # 학습
```
### 4. 일반선형모델 (Genearal Linear Model) 
* 잔차이탈도(Residual Deviation)을 제공한다.
* statsmodels.formula.api 모듈에서는 ```glm()```
* statsmodels.api 모듈에서는 ```sm.GLM()```
* 모델 파라미터에 family 변수가 추가됨
*   선형회귀: ```glm(..., family=sm.families.Gaussian())```
*   로지스틱회귀: ```glm(..., family=sm.families.Binomial())```
```python


```

